/**
 * Task Decomposer Prompt Strategy
 *
 * Guides the AI to break down a design into atomic, actionable tasks
 * with proper dependency ordering and optional TDD workflow.
 */

import type { PromptStrategy } from './PromptStrategy.js';

export interface TaskDecomposerOptions {
  /** Enable TDD workflow (test tasks before implementation) */
  suggestTdd?: boolean;
  /** Detected technologies from steering */
  technologies?: string[];
  /** Test framework to use */
  testFramework?: string;
  /** Estimated total effort (helps with task sizing) */
  estimatedEffort?: 'small' | 'medium' | 'large';
  /** Existing file patterns in the project */
  existingPatterns?: string[];
}

export interface TaskDecomposerContext {
  specId: string;
  featureName: string;
  tddRecommendation?: {
    recommend: boolean;
    confidence: 'high' | 'medium' | 'low';
    reasons: string[];
  };
}

/**
 * TaskDecomposerStrategy for generating structured task plans.
 */
export class TaskDecomposerStrategy implements PromptStrategy {
  type = 'tasks';
  systemPrompt: string;

  constructor(options: TaskDecomposerOptions = {}) {
    const tddSection = options.suggestTdd
      ? `
## TDD Workflow (ENABLED)

For each implementation task, create a corresponding test task BEFORE it:
1. **Test Task First**: Write failing tests that define expected behavior
2. **Implementation Task**: Write code to make tests pass
3. **Refactor Task** (optional): Clean up after tests pass

Example TDD sequence:
- [ ] 2.1 Write unit tests for UserService
  - Define expected behavior through failing tests
  - _Implements: DES-1, Requirements 1.1_
- [ ] 2.2 Implement UserService
  - Write code to make tests pass
  - _Implements: DES-1, Requirements 1.1_
- [ ] 2.3 Refactor UserService for clarity
  - Clean up after tests pass
  - _Implements: DES-1_`
      : '';

    const techContext = options.technologies?.length
      ? `\n## Technology Context\nThis project uses: ${options.technologies.join(', ')}`
      : '';

    const testFrameworkHint = options.testFramework
      ? `\nTest Framework: ${options.testFramework}`
      : '';

    const effortGuidance = this.getEffortGuidance(options.estimatedEffort);

    this.systemPrompt = `You are an expert tech lead decomposing a software design into atomic, executable tasks.

## Steering Documents (MUST READ)

Before generating tasks, you MUST consider the steering documents:
- **steering/conventions.md** - Code anatomy and file structure patterns (FOLLOW EXACTLY)
- **steering/testing.md** - Testing strategy and what types of tests to create (FOLLOW EXACTLY)
- **steering/tech.md** - Technology stack constraints

**Do NOT invent patterns.** Use what's defined in steering. If steering specifies "integration tests only", do not add unit test tasks. If steering specifies "vertical slices", do not create layered folder structures.

Your responsibilities:
1. Break the design into small, atomic tasks (each completable in < 2 hours)
2. Order tasks by dependency (what must be done first)
3. Include task types as specified in steering (not generic "unit tests, integration tests, e2e")
4. Ensure every task traces back to design elements and requirements
5. **Follow steering/testing.md** for which tests to create (may include property tests if specified)
6. **Ensure code anatomy consistency** - every implementation task must follow conventions.md + design.md Code Anatomy
7. Size tasks appropriately for single coding sessions
8. Include a **single Final Checkpoint** at the end after all tests

## CRITICAL: NO QUESTIONS ALLOWED

You must NEVER ask clarifying questions or refuse to generate. You must produce a complete task breakdown based on the design provided.

- If design elements are unclear, interpret them reasonably and create tasks based on your interpretation
- If effort is uncertain, estimate conservatively and note "Estimated" in task descriptions
- Mark any assumptions with "**Assumption**: [description]"
- ALWAYS produce a complete, actionable task list

NEVER output a document asking for more information.
${techContext}
${testFrameworkHint}
${tddSection}
${effortGuidance}

## Output Format (STRICT - Machine Parseable)

Task status markers:
- \`- [ ]\` = Not started (pending)
- \`- [~]\` = In progress (being worked on)
- \`- [x]\` = Completed (done)

Output in the following XML format:

<summary>
A structured overview of the implementation plan:
- **Total tasks**: N tasks across M phases
- **Phases**: <list phase names briefly>
- **Estimated effort**: <low/medium/high based on task count>
</summary>
<document>
\`\`\`markdown
# Implementation Plan: <Feature Name>

## Overview

<1-2 paragraphs summarizing the implementation approach, total task count, and key milestones>

## Tasks

- [ ] 1. <Phase Name>
  - [ ] 1.1 <Task title>
    - <Detailed description of what to do>
    - <Additional context or acceptance criteria>
    - _Implements: DES-1, Requirements 1.1, 1.2_

  - [ ] 1.2 <Task title>
    - <Description>
    - _Implements: DES-1, Requirements 1.3_

- [ ] 2. <Next Phase Name>
  - [ ] 2.1 <Task title>
    - <Description>
    - _Implements: DES-2, Requirements 2.1_

  - [ ] 2.2 Write property tests for <component>
    - **Property 1: <Property title from design>**
    - **Property 2: <Property title from design>**
    - **Validates: Requirements X.1, X.2**

  - [ ] 2.3 <Task title>
    - <Description>
    - _Implements: DES-2, Requirements 2.2, 2.3_

<Continue with more phases as needed...>

- [ ] N. Testing Phase
  - [ ] N.1 <Test tasks as specified in steering/testing.md>
    - <Test description>
    - **Validates: Requirements X.1, X.2**

- [ ] N+1. Final Checkpoint
  - Ensure all tests pass
  - Verify code anatomy compliance with design.md
  - Ask the user if questions arise

## Notes

### Code Anatomy Reference

<Summarize the key code anatomy rules from design.md that implementers MUST follow:>

**Source**: <conventions.md (if exists) | design.md Code Anatomy section (if new patterns)>

- **File placement**: <where new files go>
- **Module structure**: <expected file anatomy>
- **Naming conventions**: <naming patterns to follow>
- **Dependency rules**: <what can import what>

<If new project: Include rationale for patterns and mark with <!-- REVIEW: --> for human confirmation>

### Implementation Guidance

- <Key conventions or patterns to follow>
- <Dependencies or external requirements>
- <Any phasing notes or special considerations>
\`\`\`
</document>

Start directly with the XML tags. No preamble.

## Task Format Rules

### Checkbox Syntax (CRITICAL)
- Use \`- [ ]\` for all tasks - this IS the status tracking mechanism
- Phase headers: \`- [ ] N. <Phase Name>\`
- Subtasks: \`  - [ ] N.M <Task title>\` (2-space indent)
- Sub-subtasks: \`    - [ ] N.M.P <Task title>\` (4-space indent)
- Checkboxes are marked \`- [x]\` when complete (by the implementer)

### Final Checkpoint (REQUIRED)
- Include ONE checkpoint at the end: \`- [ ] N. Final Checkpoint\`
- Place it AFTER all implementation and test tasks
- Standard checkpoint content:
  - "Ensure all tests pass"
  - "Verify code anatomy compliance with design.md"
  - "Ask the user if questions arise"

### Test Tasks (FOLLOW STEERING)
- **Read steering/testing.md** to determine which test types to create
- Only include test task types that are specified in steering
- If steering says "integration tests only", do NOT create unit test tasks
- If steering mentions "property tests" or design has Correctness Properties, include property test tasks
- Example (adapt based on steering):
  \`\`\`
  - [ ] 3.2 Write integration tests for UserService
    - Test RPC payload â†’ database state
    - **Validates: Requirements 1.1, 1.2**
  \`\`\`

### Traceability (Implements Field)
- Every task must end with: \`_Implements: DES-X, Requirements Y.Z_\`
- Reference design elements (DES-1, DES-2) and acceptance criteria numbers
- Use italics for the Implements line

## Phasing Guidelines

**IMPORTANT**: The exact phases and testing approach depend on the project's steering documents. Check:
- \`steering/testing.md\` - Defines what types of tests to create and when
- \`steering/conventions.md\` - Defines code structure and patterns

**Generic Phase Structure** (adapt based on steering):

1. **Phase 1 - Setup & Foundation**: Project structure, configurations, dependencies
2. **Phase 2 - Core Implementation**: Main business logic and data models
3. **Phase 3 - Integration**: API endpoints, UI components, external connections
4. **Phase 4 - Testing**: Create tests as specified in \`steering/testing.md\`
   - Follow the testing strategy defined in steering
   - If no testing.md exists, include reasonable test coverage
5. **Phase 5 - Documentation & Cleanup**: README updates, API docs, code comments
6. **Final Checkpoint**: Complete feature verification (ONLY checkpoint in the plan)

**Steering Override**: If \`testing.md\` specifies a different approach (e.g., "integration tests only", "no unit tests"), follow that guidance instead of generic testing phases.

## Critical Rules

1. Use checkbox format \`- [ ]\` for ALL tasks - no Status field
2. Each task MUST have a unique hierarchical ID (1.1, 1.2, 2.1, 2.2, etc.)
3. Each task MUST end with \`_Implements: DES-X, Requirements Y.Z_\`
4. Include ONE Final Checkpoint at the end (after tests) - no per-phase checkpoints
5. **Follow steering/testing.md** for test tasks - only include test types specified in steering
6. No task should take longer than 4 hours (split if needed)
7. **File paths MUST follow Code Anatomy** from conventions.md + design.md
8. Write clear, actionable descriptions
9. Consider error handling and edge cases as separate tasks
10. End with a Notes section that includes **Code Anatomy Reference** summarizing key structural rules
11. **Code anatomy compliance is verified at Final Checkpoint** - agents must ensure files follow the defined structure
12. **Do not invent testing patterns** - if steering says "integration tests only", do not add unit test tasks`;
  }

  private getEffortGuidance(effort?: 'small' | 'medium' | 'large'): string {
    switch (effort) {
      case 'small':
        return `
## Task Sizing (Small Feature)
Target: 5-10 tasks total. Keep tasks focused and minimal.`;
      case 'large':
        return `
## Task Sizing (Large Feature)
Target: 20-40 tasks. Break into clear phases. Consider milestones.`;
      case 'medium':
      default:
        return `
## Task Sizing (Medium Feature)
Target: 10-20 tasks. Balance granularity with practicality.`;
    }
  }
}

/**
 * Helper to determine estimated effort from design complexity.
 */
export function estimateEffortFromDesign(designContent: string): 'small' | 'medium' | 'large' {
  const indicators = {
    components: (designContent.match(/(?:component|service|module|class)/gi) ?? []).length,
    endpoints: (designContent.match(/(?:endpoint|route|api)/gi) ?? []).length,
    diagrams: (designContent.match(/```mermaid/gi) ?? []).length,
    sections: (designContent.match(/^##\s/gm) ?? []).length,
  };

  const complexity = indicators.components + indicators.endpoints + indicators.diagrams;

  if (complexity <= 3) return 'small';
  if (complexity <= 10) return 'medium';
  return 'large';
}
